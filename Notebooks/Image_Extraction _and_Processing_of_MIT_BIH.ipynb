{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wfdb\n",
    "from wfdb import processing\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from ecgdetectors import Detectors\n",
    "import biosppy\n",
    "import cv2\n",
    "from biosppy.signals import ecg\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 357  650  934 1219 1502 1797 2032 2390 2693 2985 3270 3547 3850 4158\n",
      " 4453 4752 5048 5334 5621 5906 6202 6514 6811 7093 7379 7657 7940 8233\n",
      " 8526 8825 9129 9419 9698]\n"
     ]
    }
   ],
   "source": [
    "record = wfdb.rdrecord('./100', sampfrom=0, sampto=10000, channels=[0])\n",
    "qrs_inds = processing.qrs.gqrs_detect(sig=record.p_signal[:,0], fs=record.fs)\n",
    "print(qrs_inds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def peaks_hr(sig, peak_inds, fs, title, figsize=(20, 10), saveto=None):\n",
    "    \"Plot a signal with its peaks and heart rate\"\n",
    "    # Calculate heart rate\n",
    "    hrs = processing.hr.compute_hr(sig_len=sig.shape[0], qrs_inds=peak_inds, fs=fs)\n",
    "    \n",
    "    N = sig.shape[0]\n",
    "    \n",
    "    fig, ax_left = plt.subplots(figsize=figsize)\n",
    "    ax_right = ax_left.twinx()\n",
    "    \n",
    "    ax_left.plot(sig, color='#3979f0', label='Signal')\n",
    "    ax_left.plot(peak_inds, sig[peak_inds], 'rx', marker='x', \n",
    "                 color='#8b0000', label='Peak', markersize=12)\n",
    "    ax_right.plot(np.arange(N), hrs, label='Heart rate', color='m', linewidth=2)\n",
    "\n",
    "    ax_left.set_title(title)\n",
    "\n",
    "    ax_left.set_xlabel('Time (ms)')\n",
    "    ax_left.set_ylabel('ECG (mV)', color='#3979f0')\n",
    "    ax_right.set_ylabel('Heart rate (bpm)', color='m')\n",
    "    # Make the y-axis label, ticks and tick labels match the line color.\n",
    "    ax_left.tick_params('y', colors='#3979f0')\n",
    "    ax_right.tick_params('y', colors='m')\n",
    "    if saveto is not None:\n",
    "        plt.savefig(saveto, dpi=600)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peaks_hr(sig=record.p_signal, peak_inds=qrs_inds, fs=record.fs,\n",
    "         title=\"GQRS peak detection on record 100\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QRS detection in ecg using wfdb library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_bpm = 20\n",
    "max_bpm = 230\n",
    "#min_gap = record.fs * 60 / min_bpm\n",
    "# Use the maximum possible bpm as the search radius\n",
    "search_radius = int(record.fs * 60 / max_bpm)\n",
    "corrected_peak_inds = processing.peaks.correct_peaks(record.p_signal[:,0], \n",
    "                                                     peak_inds=qrs_inds,\n",
    "                                                     search_radius=search_radius, \n",
    "                                                     smooth_window_size=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Corrected GQRS detected peak indices:', sorted(corrected_peak_inds))\n",
    "peaks_hr(sig=record.p_signal, peak_inds=sorted(corrected_peak_inds), fs=record.fs,\n",
    "         title=\"Corrected GQRS peak detection on sampledata/100\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig, fields = wfdb.rdsamp('./100', channels=[0], sampto=15000)\n",
    "ann_ref = wfdb.rdann('./100','atr', sampto=15000)\n",
    "unfiltered_ecg = sig[:, 0]  \n",
    "# Run QRS detection on signal\n",
    "xqrs = processing.XQRS(sig=sig[:,0], fs=fields['fs'])\n",
    "xqrs.detect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(fields)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detecting the R_peaks using py-ecg-detectors 1.0.2\n",
    "## The r signals are found to be present in various locations in the above plotted graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detectors = Detectors(360)\n",
    "r_peaks = detectors.christov_detector(unfiltered_ecg)\n",
    "print(\"Christov r_peaks value.....\")\n",
    "print(r_peaks)\n",
    "print(\"\\n\")\n",
    "\n",
    "#hamilton algorithm\n",
    "r_peaks1 = detectors.hamilton_detector(unfiltered_ecg)\n",
    "print(\"Hamilton r_peaks value.....\")\n",
    "print(r_peaks1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The below code shows us the annotated symbols that are presented in the MIT BIH database.\n",
    "### The annoted values read from rdann is used to list the annotations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wfdb.show_ann_labels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "record = wfdb.rdrecord('./100',\n",
    "                       sampfrom=300, sampto=1000)\n",
    "wfdb.plot_wfdb(record, title='Record p000878/3269321_0001') \n",
    "display(record.__dict__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The above code contains the details that are found in the .hea file\n",
    "## The following are the explanations for the above values in the dictionary...\n",
    "\n",
    "###  Attributes\n",
    "    p_signal : ndarray\n",
    "        An (MxN) 2d numpy array, where M is the signal length. Gives the\n",
    "        physical signal values intended to be written. Either p_signal or\n",
    "        d_signal must be set, but not both. If p_signal is set, this method will\n",
    "        use it to perform analogue-digital conversion, writing the resultant\n",
    "        digital values to the dat file(s). If fmt is set, gain and baseline must\n",
    "        be set or unset together. If fmt is unset, gain and baseline must both\n",
    "        be unset.\n",
    "    d_signal : ndarray\n",
    "        An (MxN) 2d numpy array, where M is the signal length. Gives the\n",
    "        digital signal values intended to be directly written to the dat\n",
    "        file(s). The dtype must be an integer type. Either p_signal or d_signal\n",
    "        must be set, but not both. In addition, if d_signal is set, fmt, gain\n",
    "        and baseline must also all be set.\n",
    "    p_signal : ndarray\n",
    "        The expanded physical conversion of the signal. Either a 2d numpy\n",
    "        array or a list of 1d numpy arrays.\n",
    "    e_d_signal : ndarray\n",
    "        The expanded digital conversion of the signal. Either a 2d numpy\n",
    "        array or a list of 1d numpy arrays.\n",
    "    record_name : str\n",
    "        The name of the WFDB record to be read, without any file\n",
    "        extensions. If the argument contains any path delimiter\n",
    "        characters, the argument will be interpreted as PATH/BASE_RECORD.\n",
    "        Both relative and absolute paths are accepted. If the `pn_dir`\n",
    "        parameter is set, this parameter should contain just the base\n",
    "        record name, and the files fill be searched for remotely.\n",
    "        Otherwise, the data files will be searched for in the local path.\n",
    "    n_sig : int\n",
    "        Total number of signals.\n",
    "    fs : float\n",
    "        The sampling frequency of the record.\n",
    "    counter_freq : float\n",
    "        The frequency used to start counting.\n",
    "    base_counter : float\n",
    "        The counter used at the start of the file.\n",
    "    sig_len : int\n",
    "        The total length of the signal.\n",
    "    base_time : str\n",
    "        A string of the record's start time in 24h 'HH:MM:SS(.ms)' format.\n",
    "    base_date : str\n",
    "        A string of the record's start date in 'DD/MM/YYYY' format.\n",
    "    file_name : str\n",
    "        The name of the file used for analysis.\n",
    "    fmt : list\n",
    "        A list of strings giving the WFDB format of each file used to store each\n",
    "        channel. Accepted formats are: '80','212\",'16','24', and '32'. There are\n",
    "        other WFDB formats as specified by:\n",
    "        https://www.physionet.org/physiotools/wag/signal-5.htm\n",
    "        but this library will not write (though it will read) those file types.\n",
    "    samps_per_frame : int\n",
    "        The total number of samples per frame.\n",
    "    skew : float\n",
    "        The offset used to allign signals.\n",
    "    byte_offset\n",
    "        The byte offset used to allign signals.\n",
    "    adc_gain : list\n",
    "        A list of numbers specifying the ADC gain.\n",
    "    baseline : list\n",
    "        A list of integers specifying the digital baseline.\n",
    "    units : list\n",
    "        A list of strings giving the units of each signal channel.  \n",
    "    adc_res: int\n",
    "        The value produced by the ADC given a given Volt input.  \n",
    "    adc_zero: int\n",
    "        The value produced by the ADC given a 0 Volt input.\n",
    "    init_value : list\n",
    "        The initial value of the signal.\n",
    "    checksum : list, int\n",
    "        The checksum of the signal.\n",
    "    block_size : str\n",
    "        The dimensions of the field data.\n",
    "    sig_name :\n",
    "        A list of strings giving the signal name of each signal channel.\n",
    "    comments : list, optional\n",
    "        A list of string comments to be written to the header file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "record = wfdb.rdrecord('./100')\n",
    "wfdb.plot_wfdb(record=record, title='Record p000878/3269321_0001') \n",
    "display(record.__dict__)\n",
    "\n",
    "# Can also read the same files hosted on Physionet (takes long to stream the many large files)\n",
    "signals, fields = wfdb.rdsamp('100')\n",
    "wfdb.plot_items(signal=signals, fs=fields['fs'], title='Record p000878/3269321_0001')\n",
    "display((signals, fields))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Biosspy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = ecg.ecg(signal=unfiltered_ecg, sampling_rate=360., show=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segmentation_images(data):\n",
    "    path = \"ECG_image\"\n",
    "    output = []\n",
    "    flag = 1\n",
    "    APC, NORMAL, LBB, PVC, PAB, RBB, VEB = [], [], [], [], [], [], []\n",
    "    output.append(str(path))\n",
    "    result = {\"APC\": APC, \"Normal\": NORMAL, \"LBB\": LBB, \"PAB\": PAB, \"PVC\": PVC, \"RBB\": RBB, \"VEB\": VEB}\n",
    "\n",
    "        \n",
    "    indices = []\n",
    "        \n",
    "    kernel = np.ones((4,4),np.uint8)\n",
    "        \n",
    "    #csv = pd.read_csv(path)\n",
    "    #csv_data = csv[' Sample Value']\n",
    "    #data = np.array(csv_data)\n",
    "    signals = []\n",
    "    count = 1\n",
    "    peaks =  biosppy.signals.ecg.christov_segmenter(signal=data, sampling_rate = 200)[0]\n",
    "    for i in (peaks[1:-1]):\n",
    "        diff1 = abs(peaks[count - 1] - i)\n",
    "        diff2 = abs(peaks[count + 1]- i)\n",
    "        x = peaks[count - 1] + diff1//2\n",
    "        y = peaks[count + 1] - diff2//2\n",
    "        signal = data[x:y]\n",
    "        signals.append(signal)\n",
    "        count += 1\n",
    "        indices.append((x,y))\n",
    "    \n",
    "            \n",
    "        for count, i in enumerate(signals):\n",
    "            fig = plt.figure(frameon=False)\n",
    "            plt.plot(i) \n",
    "            plt.xticks([]), plt.yticks([])\n",
    "            for spine in plt.gca().spines.values():\n",
    "                spine.set_visible(False)\n",
    "\n",
    "            filename = 'fig' + '.png'\n",
    "            fig.savefig(filename)\n",
    "            im_gray = cv2.imread(filename, cv2.IMREAD_GRAYSCALE)\n",
    "            im_gray = cv2.erode(im_gray,kernel,iterations = 1)\n",
    "            im_gray = cv2.resize(im_gray, (128, 128), interpolation = cv2.INTER_LANCZOS4)\n",
    "            cv2.imwrite(filename, im_gray)\n",
    "            im_gray = cv2.imread(filename)\n",
    "            print(\"processing..\")\n",
    "            \n",
    "            '''\n",
    "            pred = model.predict(im_gray.reshape((1, 128, 128, 3)))\n",
    "            pred_class = pred.argmax(axis=-1)\n",
    "            if pred_class == 0:\n",
    "                APC.append(indices[count]) \n",
    "            elif pred_class == 1:\n",
    "                NORMAL.append(indices[count]) \n",
    "            elif pred_class == 2:    \n",
    "                LBB.append(indices[count])\n",
    "            elif pred_class == 3:\n",
    "                PAB.append(indices[count])\n",
    "            elif pred_class == 4:\n",
    "                PVC.append(indices[count])\n",
    "            elif pred_class == 5:\n",
    "                RBB.append(indices[count]) \n",
    "            elif pred_class == 6:\n",
    "                VEB.append(indices[count])\n",
    "        '''\n",
    "\n",
    "\n",
    "        result = sorted(result.items(), key = lambda y: len(y[1]))[::-1]   \n",
    "        output.append(result)\n",
    "        data = {}\n",
    "        data['filename'+ str(flag)] = str(path)\n",
    "        data['result'+str(flag)] = str(result)\n",
    "\n",
    "        json_filename = 'data.txt'\n",
    "        with open(json_filename, 'a+') as outfile:\n",
    "            json.dump(data, outfile) \n",
    "        flag+=1\n",
    "        \n",
    "   \n",
    "         \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Biosppy library for r_peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wfdb\n",
    "from wfdb import processing\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from ecgdetectors import Detectors\n",
    "import biosppy\n",
    "import cv2\n",
    "from biosppy.signals import ecg\n",
    "import json\n",
    "import glob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_records():\n",
    "    \"\"\" Get paths for data in data/mit/ directory \"\"\"\n",
    "    #Download if doesn't exist\n",
    "    \n",
    "    # There are 3 files for each record\n",
    "    # *.atr is one of them\n",
    "    paths = glob.glob('./*.atr')\n",
    "\n",
    "    # Get rid of the extension\n",
    "    paths = [path[:-4] for path in paths]\n",
    "    paths.sort()\n",
    "\n",
    "    return paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = get_records()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''directory = \"./Sample_images/r_peaks\"\n",
    "def segmentation(records):\n",
    "    signals = []\n",
    "    for e in records:\n",
    "        sig, fields = wfdb.rdsamp(e, channels = [0]) \n",
    "        data = sig[:, 0]\n",
    "        count = 1\n",
    "        peaks =  biosppy.signals.ecg.christov_segmenter(signal=data, sampling_rate = 200)[0]\n",
    "        for i in (peaks[1:-1]):\n",
    "            diff1 = abs(peaks[count - 1] - i)\n",
    "            diff2 = abs(peaks[count + 1]- i)\n",
    "            x = peaks[count - 1] + diff1//2\n",
    "            y = peaks[count + 1] - diff2//2\n",
    "            signal = data[x:y]\n",
    "            signals.append(signal)\n",
    "            count += 1\n",
    "        return signals\n",
    "    \n",
    "def ploting(Normal):\n",
    "        for count, i in enumerate(Normal):\n",
    "            fig = plt.figure(frameon=False)\n",
    "            plt.plot(i)\n",
    "            plt.xticks([]), plt.yticks([])\n",
    "            for spine in plt.gca().spines.values():\n",
    "                spine.set_visible(False)\n",
    "            filename = directory + '/' + str(count)+'.png'\n",
    "            fig.savefig(filename)\n",
    "            im_gray = cv2.imread(filename, cv2.IMREAD_GRAYSCALE)\n",
    "            im_gray = cv2.resize(im_gray, (128, 128), interpolation = cv2.INTER_LANCZOS4)\n",
    "            cv2.imwrite(filename, im_gray)\n",
    "            \n",
    "  '''  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = \"./Sample_images/r_peaks\"\n",
    "def segmentation(records):\n",
    "    Normal = []\n",
    "    for e in records:\n",
    "        signals, fields = wfdb.rdsamp(e, channels = [0]) \n",
    "\n",
    "        ann = wfdb.rdann(e, 'atr')\n",
    "        good = ['N']\n",
    "        ids = np.in1d(ann.symbol, good)\n",
    "        imp_beats = ann.sample[ids]\n",
    "        beats = (ann.sample)\n",
    "        for i in imp_beats:\n",
    "            beats = list(beats)\n",
    "            j = beats.index(i)\n",
    "            if(j!=0 and j!=(len(beats)-1)):\n",
    "                x = beats[j-1]\n",
    "                y = beats[j+1]\n",
    "                diff1 = abs(x - beats[j])//2\n",
    "                diff2 = abs(y - beats[j])//2\n",
    "                Normal.append(signals[beats[j] - diff1: beats[j] + diff2, 0])\n",
    "        return Normal\n",
    "    \n",
    "    \n",
    "def r_peaks(Normal):\n",
    "    data = np.array(Normal)\n",
    "    signals = []\n",
    "    count = 1\n",
    "    peaks =  biosppy.signals.ecg.christov_segmenter(signal=data, sampling_rate = 200)[0]\n",
    "    for i in (peaks[1:-1]):\n",
    "        diff1 = abs(peaks[count - 1] - i)\n",
    "        diff2 = abs(peaks[count + 1]- i)\n",
    "        x = peaks[count - 1] + diff1//2\n",
    "        y = peaks[count + 1] - diff2//2\n",
    "        signal = data[x:y]\n",
    "        signals.append(signal)\n",
    "        count += 1\n",
    "    return signals\n",
    "\n",
    "def ploting(Normal):\n",
    "        for count, i in enumerate(Normal):\n",
    "            fig = plt.figure(frameon=False)\n",
    "            plt.plot(i)\n",
    "            plt.xticks([]), plt.yticks([])\n",
    "            for spine in plt.gca().spines.values():\n",
    "                spine.set_visible(False)\n",
    "            filename = directory + '/' + str(count)+'.png'\n",
    "            fig.savefig(filename)\n",
    "            im_gray = cv2.imread(filename, cv2.IMREAD_GRAYSCALE)\n",
    "            im_gray = cv2.resize(im_gray, (128, 128), interpolation = cv2.INTER_LANCZOS4)\n",
    "            cv2.imwrite(filename, im_gray)\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "Normal  = segmentation(paths)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
